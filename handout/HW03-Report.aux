\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\newlabel{fig:val_pred_given_nn_1}{{\caption@xref {fig:val_pred_given_nn_1}{ on input line 127}}{2}{}{figure.caption.2}{}}
\newlabel{sub@fig:val_pred_given_nn_1}{{}{2}{}{figure.caption.2}{}}
\newlabel{fig:val_pred_given_nn_2}{{\caption@xref {fig:val_pred_given_nn_2}{ on input line 132}}{2}{}{figure.caption.2}{}}
\newlabel{sub@fig:val_pred_given_nn_2}{{}{2}{}{figure.caption.2}{}}
\newlabel{fig:val_pred_given_nn_3}{{\caption@xref {fig:val_pred_given_nn_3}{ on input line 137}}{2}{}{figure.caption.2}{}}
\newlabel{sub@fig:val_pred_given_nn_3}{{}{2}{}{figure.caption.2}{}}
\newlabel{fig:val_pred_given_nn_3}{{\caption@xref {fig:val_pred_given_nn_3}{ on input line 142}}{2}{}{figure.caption.2}{}}
\newlabel{sub@fig:val_pred_given_nn_3}{{}{2}{}{figure.caption.2}{}}
\newlabel{fig:val_pred_given_nn_3}{{\caption@xref {fig:val_pred_given_nn_3}{ on input line 147}}{2}{}{figure.caption.2}{}}
\newlabel{sub@fig:val_pred_given_nn_3}{{}{2}{}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Validation set outputs with their predictions for the first 5 validation sets using the given neural network architecture.\relax }}{2}{figure.caption.2}\protected@file@percent }
\newlabel{fig:five_graphs}{{1}{2}{Validation set outputs with their predictions for the first 5 validation sets using the given neural network architecture.\relax }{figure.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Mean squared error loss on training and validation sets for the given model architecture.\relax }}{2}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:loss_train_val_given_nn}{{1}{2}{Mean squared error loss on training and validation sets for the given model architecture.\relax }{table.caption.1}{}}
\newlabel{fig:lr_curve_2layer_nn_adam_1}{{2a}{3}{lr=0.0001\relax }{figure.caption.4}{}}
\newlabel{sub@fig:lr_curve_2layer_nn_adam_1}{{a}{3}{lr=0.0001\relax }{figure.caption.4}{}}
\newlabel{fig:lr_curve_2layer_nn_adam_2}{{2b}{3}{lr=0.001\relax }{figure.caption.4}{}}
\newlabel{sub@fig:lr_curve_2layer_nn_adam_2}{{b}{3}{lr=0.001\relax }{figure.caption.4}{}}
\newlabel{fig:lr_curve_2layer_nn_adam_3}{{2c}{3}{lr=0.01\relax }{figure.caption.4}{}}
\newlabel{sub@fig:lr_curve_2layer_nn_adam_3}{{c}{3}{lr=0.01\relax }{figure.caption.4}{}}
\newlabel{fig:lr_curve_2layer_nn_adam_4}{{2d}{3}{lr=0.1\relax }{figure.caption.4}{}}
\newlabel{sub@fig:lr_curve_2layer_nn_adam_4}{{d}{3}{lr=0.1\relax }{figure.caption.4}{}}
\newlabel{fig:lr_curve_2layer_nn_adam_5}{{2e}{3}{lr=1.0\relax }{figure.caption.4}{}}
\newlabel{sub@fig:lr_curve_2layer_nn_adam_5}{{e}{3}{lr=1.0\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Learning rate curve for a 2 hiddel layer NN model with Adam optimizer for varying learning\_rate values.\relax }}{3}{figure.caption.4}\protected@file@percent }
\newlabel{fig:lr_curve_2layer_nn_adam}{{2}{3}{Learning rate curve for a 2 hiddel layer NN model with Adam optimizer for varying learning\_rate values.\relax }{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Effect of learning rate on final validation loss for 2 layer NN model.\relax }}{3}{table.caption.3}\protected@file@percent }
\newlabel{tab:2layer_nn_adam_lr_effects}{{2}{3}{Effect of learning rate on final validation loss for 2 layer NN model.\relax }{table.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Effects of number of hidden units on learning rate for 1 layer NN model.\relax }}{3}{table.caption.5}\protected@file@percent }
\newlabel{tab:1layer_nn_adam_hunits_effects}{{3}{3}{Effects of number of hidden units on learning rate for 1 layer NN model.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Effects of filter size on 2 block CNN model. Same filter size is used for both blocks.\relax }}{4}{table.caption.6}\protected@file@percent }
\newlabel{tab:2block_cnn_num_filter_effects}{{4}{4}{Effects of filter size on 2 block CNN model. Same filter size is used for both blocks.\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Effects of kernel size on 2 block CNN model. Same kernel size is used for both blocks.\relax }}{4}{table.caption.6}\protected@file@percent }
\newlabel{tab:2block_cnn_kernel_size_effects}{{5}{4}{Effects of kernel size on 2 block CNN model. Same kernel size is used for both blocks.\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Effects of Maxpool size on 2 block CNN model. Same maxpool size is used for both blocks.\relax }}{4}{table.caption.7}\protected@file@percent }
\newlabel{tab:2block_cnn_maxpool_size_effects}{{6}{4}{Effects of Maxpool size on 2 block CNN model. Same maxpool size is used for both blocks.\relax }{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Effects of hidden layer size RNN model with LSTM cells.\relax }}{4}{table.caption.8}\protected@file@percent }
\newlabel{tab:rnn_1hl_hidden_units_effects}{{7}{4}{Effects of hidden layer size RNN model with LSTM cells.\relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Effects of hidden layer size RNN model with LSTM cells.\relax }}{4}{table.caption.9}\protected@file@percent }
\newlabel{tab:rnn_2hl_hidden_units_effects}{{8}{4}{Effects of hidden layer size RNN model with LSTM cells.\relax }{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture diagram for the best model: a multi layer neural network.\relax }}{5}{figure.caption.10}\protected@file@percent }
\newlabel{fig:best_nn}{{3}{5}{Architecture diagram for the best model: a multi layer neural network.\relax }{figure.caption.10}{}}
\newlabel{fig:best_nn_val_pred_1}{{\caption@xref {fig:best_nn_val_pred_1}{ on input line 337}}{5}{}{figure.caption.11}{}}
\newlabel{sub@fig:best_nn_val_pred_1}{{}{5}{}{figure.caption.11}{}}
\newlabel{fig:best_nn_val_pred_2}{{\caption@xref {fig:best_nn_val_pred_2}{ on input line 342}}{5}{}{figure.caption.11}{}}
\newlabel{sub@fig:best_nn_val_pred_2}{{}{5}{}{figure.caption.11}{}}
\newlabel{fig:best_nn_val_pred_3}{{\caption@xref {fig:best_nn_val_pred_3}{ on input line 347}}{5}{}{figure.caption.11}{}}
\newlabel{sub@fig:best_nn_val_pred_3}{{}{5}{}{figure.caption.11}{}}
\newlabel{fig:best_nn_val_pred_4}{{\caption@xref {fig:best_nn_val_pred_4}{ on input line 352}}{5}{}{figure.caption.11}{}}
\newlabel{sub@fig:best_nn_val_pred_4}{{}{5}{}{figure.caption.11}{}}
\newlabel{fig:best_nn_val_pred_5}{{\caption@xref {fig:best_nn_val_pred_5}{ on input line 357}}{5}{}{figure.caption.11}{}}
\newlabel{sub@fig:best_nn_val_pred_5}{{}{5}{}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Validation data output and predictions for the first 5 sets using the best model.\relax }}{5}{figure.caption.11}\protected@file@percent }
\newlabel{fig:best_nn_val_pred}{{4}{5}{Validation data output and predictions for the first 5 sets using the best model.\relax }{figure.caption.11}{}}
